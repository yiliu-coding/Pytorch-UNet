{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "# from tqdm.auto import tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.dataset import BasicDataset\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "dir_img = 'data/train_images_256/'\n",
    "dir_mask = 'data/train_masks_256/'\n",
    "dir_checkpoint = 'checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_net(net,\n",
    "              device,\n",
    "              epochs=5,\n",
    "              batch_size=8,\n",
    "              lr=0.001,\n",
    "              val_percent=0.1,\n",
    "              save_cp=True,\n",
    "              img_scale=0.5):\n",
    "\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train, val = random_split(dataset, [n_train, n_val])\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
    "    global_step = 0\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_cp}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "    ''')\n",
    "\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
    "    if net.n_classes > 1:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                imgs = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "                assert imgs.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "                mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
    "                # mask_type = torch.long\n",
    "                true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "                \n",
    "                \n",
    "                masks_softmax = net(imgs)\n",
    "                \n",
    "                # print(np.shape(masks_softmax),np.shape(true_masks))\n",
    "                # true_masks[b,1, H, W], remove 1 to call cross_entropy_loss\n",
    "                if len(np.shape(true_masks)) == 4:\n",
    "                    loss = criterion(masks_softmax, true_masks.squeeze_(1)) \n",
    "                elif len(np.shape(true_masks)) == 3:                    \n",
    "                    loss = criterion(masks_softmax, true_masks)\n",
    "                else:\n",
    "                    print(\"Minibatch size error\")\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "                optimizer.step()\n",
    "\n",
    "                pbar.update(imgs.shape[0])\n",
    "                global_step += 1\n",
    "                if global_step % (len(dataset) // (10 * batch_size)) == 0:\n",
    "                    for tag, value in net.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
    "                        writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
    "                    val_score = eval_net(net, val_loader, device)\n",
    "                    scheduler.step(val_score)\n",
    "                    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "\n",
    "                    if net.n_classes > 1:\n",
    "                        logging.info('Validation cross entropy: {}'.format(val_score))\n",
    "                        writer.add_scalar('Loss/test', val_score, global_step)\n",
    "                    else:\n",
    "                        logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
    "                        writer.add_scalar('Dice/test', val_score, global_step)\n",
    "\n",
    "                    writer.add_images('images', imgs, global_step)\n",
    "                    if net.n_classes == 1:\n",
    "                        writer.add_images('masks/true', true_masks, global_step)\n",
    "                        writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
    "\n",
    "        if save_cp:\n",
    "            try:\n",
    "                os.mkdir(dir_checkpoint)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            torch.save(net.state_dict(),\n",
    "                       dir_checkpoint + f'CP_epoch{epoch + 1}.pth')\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks',\n",
    "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('-e', '--epochs', metavar='E', type=int, default=5,\n",
    "                        help='Number of epochs', dest='epochs')\n",
    "    parser.add_argument('-b', '--batch-size', metavar='B', type=int, nargs='?', default=1,\n",
    "                        help='Batch size', dest='batchsize')\n",
    "    parser.add_argument('-l', '--learning-rate', metavar='LR', type=float, nargs='?', default=0.1,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('-f', '--load', dest='load', type=str, default=False,\n",
    "                        help='Load model from a .pth file')\n",
    "    parser.add_argument('-s', '--scale', dest='scale', type=float, default=0.5,\n",
    "                        help='Downscaling factor of the images')\n",
    "    parser.add_argument('-v', '--validation', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    \n",
    "    sys.argv[1:] = ['--epochs','50',  '--batch-size','1',  '--learning-rate','0.05',  \n",
    "                    '--load', 'False',  '--scale','0.5', '--validation','10.0']\n",
    "    # Or simply\n",
    "    # sys.argv[1:] = ['-e','2',  '-b','4',  '-l','0.1', '-f', 'False',  '?-s','0.5', '-v','10.0']\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cuda\n",
      "INFO: Network:\n",
      "\t1 input channels\n",
      "\t8 output channels (classes)\n",
      "\tBilinear upscaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchsize=1, epochs=50, load='False', lr=0.05, scale=0.5, val=10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Creating dataset with 790 examples\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0529 03:20:49.775973 140014554785600 <ipython-input-3-e2ec59991c43>:29] Starting training:\n",
      "        Epochs:          50\n",
      "        Batch size:      1\n",
      "        Learning rate:   0.05\n",
      "        Training size:   711\n",
      "        Validation size: 79\n",
      "        Checkpoints:     True\n",
      "        Device:          cuda\n",
      "        Images scaling:  0.5\n",
      "    \n",
      "Epoch 1/50:  11%|█         | 79/711 [00:03<00:24, 25.84img/s, loss (batch)=0.000464]\n",
      "Validation round:   0%|          | 0/79 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▏         | 1/79 [00:00<00:34,  2.25batch/s]\u001b[A\n",
      "Validation round:  20%|██        | 16/79 [00:00<00:19,  3.19batch/s]\u001b[A\n",
      "Validation round:  41%|████      | 32/79 [00:00<00:10,  4.52batch/s]\u001b[A\n",
      "Validation round:  61%|██████    | 48/79 [00:00<00:04,  6.38batch/s]\u001b[A\n",
      "Validation round:  81%|████████  | 64/79 [00:00<00:01,  8.95batch/s]\u001b[A\n",
      "                                                                    \u001b[AI0529 03:20:58.063655 140014554785600 <ipython-input-3-e2ec59991c43>:90] Validation cross entropy: 1.8704668971981788\n",
      "Epoch 1/50:  22%|██▏       | 157/711 [00:11<00:20, 26.64img/s, loss (batch)=0.0233]  \n",
      "Validation round:   0%|          | 0/79 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▏         | 1/79 [00:00<00:25,  3.01batch/s]\u001b[A\n",
      "Validation round:  16%|█▋        | 13/79 [00:00<00:15,  4.25batch/s]\u001b[A\n",
      "Validation round:  35%|███▌      | 28/79 [00:00<00:08,  5.99batch/s]\u001b[A\n",
      "Validation round:  56%|█████▌    | 44/79 [00:00<00:04,  8.42batch/s]\u001b[A\n",
      "Validation round:  76%|███████▌  | 60/79 [00:00<00:01, 11.76batch/s]\u001b[A\n",
      "Validation round:  99%|█████████▊| 78/79 [00:00<00:00, 16.31batch/s]\u001b[A\n",
      "                                                                    \u001b[AI0529 03:21:06.250107 140014554785600 <ipython-input-3-e2ec59991c43>:90] Validation cross entropy: 1.263225972651146\n",
      "Epoch 1/50:  33%|███▎      | 236/711 [00:19<00:18, 26.27img/s, loss (batch)=0.0161]  \n",
      "Validation round:   0%|          | 0/79 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▏         | 1/79 [00:00<00:26,  2.91batch/s]\u001b[A\n",
      "Validation round:  22%|██▏       | 17/79 [00:00<00:15,  4.12batch/s]\u001b[A\n",
      "Validation round:  43%|████▎     | 34/79 [00:00<00:07,  5.82batch/s]\u001b[A\n",
      "Validation round:  65%|██████▍   | 51/79 [00:00<00:03,  8.20batch/s]\u001b[A\n",
      "Validation round:  86%|████████▌ | 68/79 [00:00<00:00, 11.47batch/s]\u001b[A\n",
      "                                                                    \u001b[AI0529 03:21:14.222491 140014554785600 <ipython-input-3-e2ec59991c43>:90] Validation cross entropy: 0.2940518136848725\n",
      "Epoch 1/50:  44%|████▍     | 316/711 [00:27<00:15, 25.56img/s, loss (batch)=0.0047] \n",
      "Validation round:   0%|          | 0/79 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▏         | 1/79 [00:00<00:33,  2.33batch/s]\u001b[A\n",
      "Validation round:  18%|█▊        | 14/79 [00:00<00:19,  3.30batch/s]\u001b[A\n",
      "Validation round:  38%|███▊      | 30/79 [00:00<00:10,  4.67batch/s]\u001b[A\n",
      "Validation round:  57%|█████▋    | 45/79 [00:00<00:05,  6.58batch/s]\u001b[A\n",
      "Validation round:  77%|███████▋  | 61/79 [00:00<00:01,  9.23batch/s]\u001b[A\n",
      "Validation round: 100%|██████████| 79/79 [00:00<00:00, 12.90batch/s]\u001b[A\n",
      "                                                                    \u001b[AI0529 03:21:21.561048 140014554785600 <ipython-input-3-e2ec59991c43>:90] Validation cross entropy: 0.010719625740547817\n",
      "Epoch 1/50:  55%|█████▌    | 394/711 [00:34<00:11, 26.52img/s, loss (batch)=0.00323]\n",
      "Validation round:   0%|          | 0/79 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▏         | 1/79 [00:00<00:24,  3.21batch/s]\u001b[A\n",
      "Validation round:   5%|▌         | 4/79 [00:00<00:17,  4.36batch/s]\u001b[A\n",
      "Validation round:  20%|██        | 16/79 [00:00<00:10,  6.13batch/s]\u001b[A\n",
      "Validation round:  41%|████      | 32/79 [00:00<00:05,  8.60batch/s]\u001b[A\n",
      "Validation round:  59%|█████▉    | 47/79 [00:00<00:02, 11.99batch/s]\u001b[A\n",
      "Validation round:  76%|███████▌  | 60/79 [00:00<00:01, 16.45batch/s]\u001b[A\n",
      "Validation round:  97%|█████████▋| 77/79 [00:00<00:00, 22.52batch/s]\u001b[A\n",
      "                                                                    \u001b[AI0529 03:21:29.023149 140014554785600 <ipython-input-3-e2ec59991c43>:90] Validation cross entropy: 0.010701814288040623\n",
      "Epoch 1/50:  67%|██████▋   | 474/711 [00:42<00:09, 25.46img/s, loss (batch)=0.00151] \n",
      "Validation round:   0%|          | 0/79 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▏         | 1/79 [00:00<00:27,  2.81batch/s]\u001b[A\n",
      "Validation round:  22%|██▏       | 17/79 [00:00<00:15,  3.99batch/s]\u001b[A\n",
      "Validation round:  42%|████▏     | 33/79 [00:00<00:08,  5.64batch/s]\u001b[A\n",
      "Validation round:  63%|██████▎   | 50/79 [00:00<00:03,  7.94batch/s]\u001b[A\n",
      "Validation round:  81%|████████  | 64/79 [00:00<00:01, 11.06batch/s]\u001b[A\n",
      "                                                                    \u001b[AI0529 03:21:37.354031 140014554785600 <ipython-input-3-e2ec59991c43>:90] Validation cross entropy: 0.2455967461036023\n",
      "Epoch 1/50:  78%|███████▊  | 552/711 [00:50<00:06, 24.86img/s, loss (batch)=0.0133]  \n",
      "Validation round:   0%|          | 0/79 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▏         | 1/79 [00:00<00:27,  2.80batch/s]\u001b[A\n",
      "Validation round:  13%|█▎        | 10/79 [00:00<00:17,  3.95batch/s]\u001b[A\n",
      "Validation round:  30%|███       | 24/79 [00:00<00:09,  5.57batch/s]\u001b[A\n",
      "Validation round:  49%|████▉     | 39/79 [00:00<00:05,  7.83batch/s]\u001b[A\n",
      "Validation round:  70%|██████▉   | 55/79 [00:00<00:02, 10.95batch/s]\u001b[A\n",
      "Validation round:  90%|████████▉ | 71/79 [00:00<00:00, 15.19batch/s]\u001b[A\n",
      "                                                                    \u001b[AI0529 03:21:45.907651 140014554785600 <ipython-input-3-e2ec59991c43>:90] Validation cross entropy: 0.012846601273366428\n",
      "Epoch 1/50:  89%|████████▊ | 631/711 [00:59<00:03, 26.37img/s, loss (batch)=0.00234]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "    args = get_args()\n",
    "    print(args)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     device = torch.device( 'cpu')\n",
    "\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    # Change here to adapt to your data\n",
    "    # n_channels=1 for SAR data in this case, while 3 for RGB images\n",
    "    # n_classes is the number of probabilities you want to get per pixel\n",
    "    #   - For 1 class and background, use n_classes=1\n",
    "    #   - For 2 classes, use n_classes=1\n",
    "    #   - For N > 2 classes, use n_classes=N\n",
    "    net = UNet(n_channels=1, n_classes=8, bilinear=True)\n",
    "    logging.info(f'Network:\\n'\n",
    "                 f'\\t{net.n_channels} input channels\\n'\n",
    "                 f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "#     if args.load:\n",
    "#         net.load_state_dict(\n",
    "#             torch.load(args.load, map_location=device)\n",
    "#         )\n",
    "#         logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    # faster convolutions, but more memory\n",
    "    # cudnn.benchmark = True\n",
    "\n",
    "    try:\n",
    "        train_net(net=net,\n",
    "                  epochs=args.epochs,\n",
    "                  batch_size=args.batchsize,\n",
    "                  lr=args.lr,\n",
    "                  device=device,\n",
    "                  img_scale=args.scale,\n",
    "                  val_percent=args.val / 100)\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "        logging.info('Saved interrupt')\n",
    "        try:\n",
    "            sys.exit(0)\n",
    "        except SystemExit:\n",
    "            os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_torch = torch.randn(3, 3, 2, 5, requires_grad=True)\n",
    "\n",
    "# one_hot = np.array([[[1, 1, 1, 0, 2], [0, 1, 0, 2, 0]],    \n",
    "#                     [[1, 0, 0, 2, 0], [1, 1, 1, 2, 0]],])\n",
    "\n",
    "one_hot = np.array([[[1, 1, 1, 0, 0], [0, 0, 0, 0, 0]],    \n",
    "                    [[0, 0, 0, 0, 0], [1, 1, 1, 0, 0]],\n",
    "                    [[0, 0, 0, 1, 1], [0, 0, 0, 1, 1]]])\n",
    "one_hot = torch.tensor(one_hot)\n",
    "\n",
    "# one_hot = one_hot[np.newaxis,:,:,:]\n",
    "\n",
    "# one_hot = torch.argmax(one_hot, dim=1)\n",
    "# target_torch = torch.tensor(one_hot[np.newaxis,:,:,:])\n",
    "# target_torch = torch.tensor(one_hot[np.newaxis,:,:])\n",
    "\n",
    "print(np.shape(input_torch), np.shape(one_hot))\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "output = loss(input_torch, one_hot)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = np.array([[1, 1, 1, 0, 2], [0, 1, 0, 2, 0]])\n",
    "one_hot = one_hot[:,np.newaxis, np.newaxis, :]\n",
    "\n",
    "one_hot = torch.tensor(one_hot)\n",
    "print(len(np.shape(one_hot)), np.shape(one_hot))\n",
    "\n",
    "one_hot.squeeze_(1)\n",
    "print(len(np.shape(one_hot)), np.shape(one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot.dim()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
